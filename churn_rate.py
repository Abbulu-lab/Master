# -*- coding: utf-8 -*-
"""Churn_rate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12wSit8t8TbWoi0gBHaWxY8Qh1rUAKBAp

# Importing Libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# Reading CSV file
data = pd.read_excel('/content/churn.xlsx', sheet_name='E Comm')
couponData = pd.read_csv('/content/coupon.csv')

# numbers of rows in the data set
len(data)

# number of columns in the dataset
len(data.columns)

data.head(5)

couponData

# Cleaning the DataSet
data = data.fillna(0)
data.replace(np.nan, 0)

# checking the outliers in the data
data[['CityTier', 'PreferredPaymentMode', 'Gender', 'PreferedOrderCat',
      'SatisfactionScore', 'MaritalStatus',
      'Complain', 'OrderAmountHikeFromlastYear']].plot(subplots = True, kind = 'box', layout = (4,4), patch_artist = True, figsize = (20,15))

# Data Descryption
data.describe()

# plotting a heatmap to get the relations between the columns
plt.figure(figsize = (15,8))
sns.heatmap(data.corr(), annot = True, cmap = 'inferno')
plt.title('HeatMap of Data')

"""<b> VISUALIZATIONS </b>"""

sns.countplot(x = 'MaritalStatus', data= data, hue='Churn')
plt.title('Martial Status VS Churn Rate')

# 0 represents no churn in the customers and 1 represent the churn
sns.countplot(x='CityTier', data = data, hue='Churn')
plt.title('City Tier VS Churn Rate')

sns.countplot(x='Gender', data= data, hue= 'Churn')
plt.title('Gender VS Churn Rate')

sns.countplot(x='PreferredPaymentMode', data= data, hue='Churn')
plt.title('PreferredPaymentMode VS Churn Rate')

sns.countplot(x = 'PreferedOrderCat', data = data, hue='Churn')
plt.title('PreferedOrderCat VS Churn Rate')

sns.countplot(x = 'Complain', data=data, hue='Churn')

# taking out the all the data with churn users
df1 = data[data['Churn'] ==  1]

def check(col, elem):
  x = df1[df1[col] == elem]
  y = data[data[col] == elem]
  if not len(y):
    return 0
  return (len(x)/len(y))*100

"""<b> THE PERCENTAGES OF CHURN IN USERS </b>"""

# the users leaving the platform based on their Gender

print('nearly', check('Gender', 'Male'), 'males users have left the platform')
print('nearly', check('Gender', 'Female'), 'Females users have left the platform')

# the users leaving the platform based on the martitial status

print('nearly', check('MaritalStatus', 'Single'), 'users whose maritial status is single have left the platform')
print('nearly', check('MaritalStatus', 'Divorced'), 'users whose maritial status is Divorced have left the platform')
print('nearly', check('MaritalStatus', 'Married'), 'users whose maritial status is Married have left the platform')

# the users leaving the platform based on their payment mode

print('nearly', check('PreferredPaymentMode', 'Debit Card'), 'Debit Card users have left the platform')
print('nearly', check('PreferredPaymentMode', 'Cash on Delivery'), 'cash on Delivery users have left the platform')
print('nearly', check('PreferredPaymentMode', 'E wallet'), 'E Wallet users have left the platform')
print('nearly', check('PreferredPaymentMode', 'Credit Card'), 'Credit card users have left the platform')

data['PreferedOrderCat'].unique()

# users leaving the platform and their prefered ordered cat

print('The percentage of churn rate in users who ordered laptops and accesorries is', check('PreferedOrderCat', 'Laptop & Accessory'))
print('The percentage of churn rate in users who ordered Mobile is', check('PreferedOrderCat', 'Mobile'))
print('The percentage of churn rate in users who ordered Mobile is', check('PreferedOrderCat', 'Mobile Phone'))
print('The percentage of churn rate in users who ordered Fashion related items is', check('PreferedOrderCat', 'Fashion'))
print('The percentage of churn rate in users who ordered Grocery is', check('PreferedOrderCat', 'Grocery'))

# users with complain leaving the platform

print('nearly', check('Complain', 1), 'users with complaints leaving the platform')
print('nearly', check('Complain', 0), 'users with no complaints leaving the platform')

# Encoding the string data into integer data
from sklearn import preprocessing
encoder  = preprocessing.LabelEncoder()
data['GenderLabel'] = encoder.fit_transform(data['Gender'])
data['PreferredPaymentModeLabel'] = encoder.fit_transform(data['PreferredPaymentMode'])
data['PreferedOrderCatLabel'] = encoder.fit_transform(data['PreferedOrderCat'])
data['MaritalStatusLabel'] = encoder.fit_transform(data['MaritalStatus'])

# check assigned values
ge = data.groupby('Gender')
ge = ge['GenderLabel']
ge.first()

# check assigned values
pp = data.groupby('PreferredPaymentMode')
pp = pp['PreferredPaymentModeLabel']
pp.first()

# check assigned values
po = data.groupby('PreferedOrderCat')
po = po['PreferedOrderCatLabel']
po.first()

# check assigned values
ms = data.groupby('MaritalStatus')
ms = ms['MaritalStatusLabel']
ms.first()

#correlation plot
plt.figure(figsize=(20, 10))
sns.heatmap(data.corr(), annot=True, cmap='winter')

"""# Train, Test Data Spliting"""

# Getting the Features and Target Values

X = data[['CityTier', 'PreferredPaymentModeLabel', 'GenderLabel', 'PreferedOrderCatLabel', 'SatisfactionScore', 'MaritalStatusLabel',
          'Complain', 'OrderAmountHikeFromlastYear', 'CashbackAmount']]
Y = data['Churn']

couponIndependent = couponData.drop(columns="CAMPAIGN", axis=1)
couponDependent = couponData['CAMPAIGN']

X.head(10)

Xval = X.values
Yval = Y.values

# Splitting the training and testing split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(Xval, Yval, test_size= 0.25)

xTrain, xTest, yTrain, yTest = train_test_split(couponIndependent, couponDependent, test_size= 0.3)

"""# Decision Tree Model"""

from sklearn.tree import DecisionTreeClassifier
model_tree = DecisionTreeClassifier()

# Training the model
model_tree.fit(x_train, y_train)

# making predictions
pred = model_tree.predict(x_test)

# visualizing the predictions and the actual data
tree_data = pd.DataFrame()
tree_data['Predictions'] = pred
tree_data['Actual'] = y_test

plt.figure(figsize=(15,8))
sns.kdeplot(data=tree_data, linewidth=1.5)
plt.title('Actual VS Predictions Using Decision Tree Model')

# calculating the accuracy of the model
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(accuracy_score(y_test, pred))
print(classification_report(y_test, pred))
print(confusion_matrix(y_test, pred))

"""# Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
model_random = RandomForestClassifier()

# Training the data
model_random.fit(x_train, y_train)

# Making Predictions
random_pred = model_random.predict(x_test)

# Measuring the Accuracy
print('Accuracy Score', accuracy_score(y_test, random_pred))
print('\nClassification Report\n', classification_report(y_test, random_pred))
print('\n Confusion Matrix', confusion_matrix(y_test, random_pred))

# visualizing the prections and testing data
random_data = pd.DataFrame()
random_data['actual'] = y_test
random_data['Predictions'] = random_pred
plt.figure(figsize=(15,8))
sns.kdeplot(data = random_data, linewidth = 1.5)
plt.title('Actual VS Predictions Using Random Forest Model')

"""# XGBOOST MODEL"""

import xgboost as xgb
XGB_model = xgb.XGBClassifier()

# Training the model
XGB_model.fit(x_train, y_train)

# Making predictions
XGB_pred = XGB_model.predict(x_test)

# Calculating the accuracy of the model
print(accuracy_score(y_test, XGB_pred))
print('\n Classification Report \n', classification_report(y_test, XGB_pred))
print('\n Confusion Matrix \n', confusion_matrix(y_test, XGB_pred))

# Visualizing the model predictions and actual data
xgb_data = pd.DataFrame()
xgb_data['Actual'] = y_test
xgb_data['Predictions'] = XGB_pred
plt.figure(figsize = (15, 8))
sns.kdeplot(data = xgb_data, linewidth = 1.5)
plt.title('Actual VS Predictions using XGB Model')

"""# RandomForestClassifier Model on Coupon Data"""

co_model_random = RandomForestClassifier()

# Training the data
co_model_random.fit(xTrain, yTrain)

# Making Predictions
co_random_pred = co_model_random.predict(xTest)

# Measuring the Accuracy
print('Accuracy Score', accuracy_score(yTest, co_random_pred))
print('\nClassification Report\n', classification_report(yTest, co_random_pred))
print('\n Confusion Matrix', confusion_matrix(yTest, co_random_pred))

"""# Predictive System"""

# Import CSV File
predictionData = pd.read_csv('/content/predictionData.csv')
predictionData

# Predict likely to Churn or not
predictedValues = model_random.predict(predictionData)
predictionData['churnPrediction'] = predictedValues
predictionData

# In case churn is yes, assign coupon from 5 running campaign to reduce actual churn
churnYes = predictionData[predictionData['churnPrediction']==1]
churnYes=churnYes.reset_index()
churnYes.drop(columns=['index'], axis=1, inplace=True)
churnYes=churnYes.iloc[:,0:4]
couponPredictValues = co_model_random.predict(churnYes)
churnYes['couponCampaignPredict'] = couponPredictValues
churnYes

predictionData.to_csv('/content/churnPrediction.csv', index=False)
churnYes.to_csv('/content/churnYesCouponCampainPredict.csv', index=False)